name: microservice-2026

volumes:
  db-users:
    name: db-users
  db-notifications:
    name: db-notifications
  db-news:
    name: db-news
  kafka1-data:
    name: kafka1-data
  kafka2-data:
    name: kafka2-data
  kafka3-data:
    name: kafka3-data
  redis-data:
    name: redis-data

networks:
  communication:
    name: communication
    driver: bridge # Rede bridge personalizada → todos os containers se enxergam pelo nome

services:

  # ============================================================
  # Cluster Kafka - Broker 1
  # ============================================================
  kafka-1:
    image: apache/kafka:4.1.1 # Imagem oficial do Apache Kafka com KRaft nativo
    container_name: kafka-1 # Define o nome do container.
    hostname: kafka-1 # Define o nome do host na rede Docker (usado para comunicação interna).
    ports:
      - 19092:19092 # Mapeia a porta do Host (ex: localhost:19092) para a porta Interna do container (porta de escuta 19092 definida no Listener EXTERNAL).
    environment:
      KAFKA_NODE_ID: 1 # ID único do nó no cluster (obrigatório)
      KAFKA_PROCESS_ROLES: 'broker,controller' # Todos os nós são dual-role: tanto servem dados (broker - aceita producers/consumers) quanto gerenciam metadados (controller - antes era o papel do Zookeeper). Define que o nó atua como Broker (recebe mensagens) e Controller (gerencia o estado do cluster no modo KRaft).
      KAFKA_LOG_DIRS: '/var/lib/kafka/data' # Onde o Kafka grava os logs de tópicos + metadados KRaft. Em dev: /tmp → perde tudo ao reiniciar (/tmp/kraft-combined-logs). Em prod: volume persistente (/var/lib/kafka/data).

      # === LISTENERS & ADVERTISED LISTENERS ===
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT' # Comunicação entre brokers usa o listener interno na porta 9092. Os brokers conversam entre si usando o listener PLAINTEXT. Quase sempre PLAINTEXT em dev.
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT' #
      KAFKA_LISTENERS: 'PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:19092' # Define os listeners (pontos de escuta) internos do broker: PLAINTEXT (para comunicação interna broker-broker), CONTROLLER (para o quorum KRaft) e EXTERNAL (para clientes externos - seu laptop, postman e etc). Separação clara de responsabilidades.
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:9092,EXTERNAL://localhost:19092 # CRUCIAL: Diz aos clientes (como sua aplicação Spring Boot) qual endereço usar. PLAINTEXT://kafka-1:9092 (para comunicação de container para container) e EXTERNAL://localhost:19092 (para acesso de fora do Docker). O que o cliente vê: Interno: kafka-1:9092; Externo: localhost:19092 (kafka-1), 19093 (kafka-2) e 19094 (kafka-3). Containers acessam o broker pelo hostname kafka-1:9092. A sua máquina acessa pelo localhost:19092.

      # === KRaft Quorum ===
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER' # Qual listener é usado pelos controllers (porta 9093). Obrigatório no KRaft.
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093' # Lista os nós (ID@nome:porta) que participam do quorum KRaft para eleger o Controller Leader.
      CLUSTER_ID: '4L6g3nShT-eMCtK--X86sw' # Identificador único do cluster KRaft. Deve ser o mesmo para todos os brokers.

      # === PRODUÇÃO: Replicação dos tópicos internos ===
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3 # __consumer_offsets agora tem RF=3 → offsets sobrevivem mesmo se 2 brokers caírem.
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3 # Transações exactly-once sobrevivem.
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2 # Producer com acks=all só confirma quando 2 réplicas confirmarem → durabilidade forte.
      KAFKA_SHARE_COORDINATOR_STATE_TOPIC_REPLICATION_FACTOR: 3 # Para Kafka Share Groups.
      KAFKA_SHARE_COORDINATOR_STATE_TOPIC_MIN_ISR: 2 # Para Kafka Share Groups.

      # === PERFORMANCE / ESTABILIDADE ===
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

      # === SEGURANÇA ===
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'  # Evita tópicos fantasmas.
    volumes:
      - kafka1-data:/var/lib/kafka/data
    networks:
      - communication

  # ============================================================
  # Cluster Kafka - Broker 2
  # ============================================================
  kafka-2:
    image: apache/kafka:4.1.1
    container_name: kafka-2
    hostname: kafka-2
    ports:
      - 19093:19092
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_LOG_DIRS: '/var/lib/kafka/data'

      # === LISTENERS & ADVERTISED LISTENERS ===
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT'
      KAFKA_LISTENERS: 'PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:19092'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2:9092,EXTERNAL://localhost:19093

      # === KRaft Quorum ===
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093'
      CLUSTER_ID: '4L6g3nShT-eMCtK--X86sw'

      # === PRODUÇÃO: Replicação dos tópicos internos ===
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_SHARE_COORDINATOR_STATE_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_SHARE_COORDINATOR_STATE_TOPIC_MIN_ISR: 2

      # === PERFORMANCE / ESTABILIDADE ===
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

      # === SEGURANÇA ===
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
    volumes:
      - kafka2-data:/var/lib/kafka/data
    networks:
      - communication

  # ============================================================
  # Cluster Kafka - Broker 3
  # ============================================================
  kafka-3:
    image: apache/kafka:4.1.1
    container_name: kafka-3
    hostname: kafka-3
    ports:
      - 19094:19092
    environment:
      KAFKA_NODE_ID: 3
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_LOG_DIRS: '/var/lib/kafka/data'

      # === LISTENERS & ADVERTISED LISTENERS ===
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT'
      KAFKA_LISTENERS: 'PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:19092'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-3:9092,EXTERNAL://localhost:19094

      # === KRaft Quorum ===
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093'
      CLUSTER_ID: '4L6g3nShT-eMCtK--X86sw'

      # === PRODUÇÃO: Replicação dos tópicos internos ===
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_SHARE_COORDINATOR_STATE_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_SHARE_COORDINATOR_STATE_TOPIC_MIN_ISR: 2

      # === PERFORMANCE / ESTABILIDADE ===
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

      # === SEGURANÇA ===
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
    volumes:
      - kafka3-data:/var/lib/kafka/data
    networks:
      - communication

#  kafka-ui: # interface gráfica para administração da mensageria
#    image: provectuslabs/kafka-ui:latest
#    container_name: kafka-ui
#    ports:
#      - "8080:8080"
#    deploy:
#      resources:
#        limits:
#          cpus: '0.2'
#          memory: 128M
#    restart: always
#    environment:
#      DYNAMIC_CONFIG_ENABLED: true
#      KAFKA_CLUSTERS_0_NAME: wizard_cluster
#      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-1:9092,kafka-2:9092,kafka-3:9092 # Configura a UI para se conectar aos brokers Kafka usando os endereços internos da rede Docker.
#      KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL: PLAINTEXT
#    depends_on:
#      kafka-1:
#        condition: service_started
#      kafka-2:
#        condition: service_started
#      kafka-3:
#        condition: service_started
#    networks:
#      - communication

  schema-registry: # gerenciamento de schemas Avro. O Schema Registry armazena schemas no tópico _schemas. Cada schema tem um id numérico (ex: 1, 2) e é associado a um subject (ex: events.customer-created-v1-value).
    image: confluentinc/cp-schema-registry:8.1.0
    container_name: schema-registry
    ports:
      - "8081:8081"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
    restart: unless-stopped
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas # Tópico onde os schemas são salvos (padrão e correto).
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC_REPLICATION_FACTOR: 3 # O tópico _schemas agora tem RF=3 → se 2 brokers caírem, schemas continuam disponíveis.
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'PLAINTEXT://kafka-1:9092,PLAINTEXT://kafka-2:9092,PLAINTEXT://kafka-3:9092' # Diz ao Schema Registry onde ele deve armazenar os schemas (apontando para o listener PLAINTEXT dos brokers).
      SCHEMA_REGISTRY_HOST_NAME: 'schema-registry' # Usado para gerar URLs internas.
      SCHEMA_REGISTRY_LISTENERS: 'http://0.0.0.0:8081' # O Schema Registry está configurado para ouvir internamente nessa porta.
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: 'INFO'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081"]
      interval: 15s
      timeout: 5s
      start_period: 15s
      retries: 4
    depends_on:
      kafka-1:
        condition: service_started
      kafka-2:
        condition: service_started
      kafka-3:
        condition: service_started
    networks:
      - communication

  configserver:
    image: juniorsmartins/configserver:v0.0.2
    container_name: configserver
    hostname: configserver
    build:
      context: ../configserver
      dockerfile: Dockerfile
      args:
        APP_NAME: "configserver"
        APP_VERSION: "v0.0.2"
        APP_DESCRIPTION: "Microsserviço responsável por centralizar as configurações dos microsserviços."
    ports:
      - "8888:8888"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M
    environment:
      TZ: utc
      SERVER_PORT: 8888
      SPRING_CLOUD_CONFIG_ENABLED: false
      SPRING_RABBITMQ_HOST: "rabbit"
      RABBIT_HOST: rabbit
      RABBIT_PORT: 5672
      RABBIT_USER: guest
      RABBIT_PASS: guest
      JAVA_TOOL_OPTIONS: "--enable-native-access=ALL-UNNAMED" # Elimina alguns warnnings
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8888/actuator/health" ]
      interval: 10s
      timeout: 5s
      retries: 20
      start_period: 180s  # 3 minutos — dá tempo para Git clone + Kafka + Bus
      start_interval: 5s
    restart: unless-stopped
    networks:
      - communication
    depends_on:
      rabbit:
        condition: service_healthy

  eurekaserver:
    image: juniorsmartins/eurekaserver:v0.0.2
    container_name: eurekaserver
    hostname: eurekaserver
    build:
      context: ../eurekaserver
      dockerfile: Dockerfile
      args:
        APP_NAME: "eurekaserver"
        APP_VERSION: "v0.0.2"
        APP_DESCRIPTION: "Servidor de Registro e Descoberta de serviços."
    ports:
      - "8761:8761"
    deploy:
      resources:
        limits:
          cpus: '1.00'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M
    environment:
      TZ: utc
      SERVER_PORT: 8761
      JAVA_TOOL_OPTIONS: "--enable-native-access=ALL-UNNAMED" # Elimina alguns warnnings
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8761/actuator/health" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 40s
      start_interval: 5s
    restart: unless-stopped
    networks:
      - communication
    depends_on:
      configserver:
        condition: service_healthy

  gatewayserver:
    image: juniorsmartins/gatewayserver:v0.0.2
    container_name: gatewayserver
    hostname: gatewayserver
    build:
      context: ../gatewayserver
      dockerfile: Dockerfile
      args:
        APP_NAME: "gatewayserver"
        APP_VERSION: "v0.0.2"
        APP_DESCRIPTION: "Servidor Gateway para roteamento de requisições."
    ports:
      - "8765:8765"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M
    environment:
      TZ: utc
      SERVER_PORT: 8765
      EUREKA_CLIENT_SERVICEURL_DEFAULTZONE: http://eurekaserver:8761/eureka/
      JAVA_TOOL_OPTIONS: "--enable-native-access=ALL-UNNAMED" # Elimina alguns warnnings
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8765/actuator/health" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 40s
      start_interval: 5s
    restart: unless-stopped
    networks:
      - communication
    depends_on:
      configserver:
        condition: service_healthy
      eurekaserver:
        condition: service_healthy

  api-users:
    image: juniorsmartins/api-users:v0.0.2
    container_name: api-users
    hostname: api-users
    build:
      context: ../api-users
      dockerfile: Dockerfile
      args:
        APP_NAME: "api-users"
        APP_VERSION: "v0.0.2"
        APP_DESCRIPTION: "API de Usuários para segurança de sistema financeiro."
    ports:
      - "9050:9050"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    environment:
      TZ: utc
      SERVER_PORT: 9050
      SPRING_CLOUD_CONFIG_SERVER_URI: http://configserver:8888
      EUREKA_CLIENT_SERVICEURL_DEFAULTZONE: http://eurekaserver:8761/eureka/
      SPRING_PROFILES_ACTIVE: dev
      SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      SPRING_KAFKA_PROPERTIES_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      DB_HOST: database-users
      DB_NAME: db-users
      DB_PORT: 5432
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      SPRING_RABBITMQ_HOST: "rabbit"
      RABBIT_HOST: rabbit
      RABBIT_PORT: 5672
      RABBIT_USER: guest
      RABBIT_PASS: guest
      JAVA_TOOL_OPTIONS: "--enable-native-access=ALL-UNNAMED" # Elimina alguns warnnings
    restart: unless-stopped
    networks:
      - communication
    depends_on:
      database-users:
        condition: service_started
      schema-registry:
        condition: service_healthy
      configserver:
        condition: service_healthy
      eurekaserver:
        condition: service_healthy

  database-users:
    image: postgres:17.0
    container_name: database-users
    hostname: database-users
    ports:
      - "5501:5432"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
    restart: unless-stopped
    environment:
      TZ: utc
      POSTGRES_DB: db-users
#      POSTGRES_MULTIPLE_DATABASES: db_user, db_outro1, db_outro2
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    volumes:
      - db-users:/var/lib/postgresql/data
    networks:
      - communication

  api-notifications:
    image: juniorsmartins/api-notifications:v0.0.2
    container_name: api-notifications
    hostname: api-notifications
    build:
      context: ../api-notifications
      dockerfile: Dockerfile
      args:
        APP_NAME: "api-notifications"
        APP_VERSION: "v0.0.2"
        APP_DESCRIPTION: "API para notificações de cliente via email."
    ports:
      - "9060:9060"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
    environment:
      TZ: utc
      SERVER_PORT: 9060
      SPRING_CLOUD_CONFIG_SERVER_URI: http://configserver:8888
      EUREKA_CLIENT_SERVICEURL_DEFAULTZONE: http://eurekaserver:8761/eureka/
      SPRING_PROFILES_ACTIVE: dev
      SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      SPRING_KAFKA_PROPERTIES_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      DB_HOST: database-notifications
      DB_PORT: 3306
      DB_NAME: db-notifications
      MARIADB_USER: mariadb
      MARIADB_PASSWORD: mariadb
      SPRING_RABBITMQ_HOST: "rabbit"
      RABBIT_HOST: rabbit
      RABBIT_PORT: 5672
      RABBIT_USER: guest
      RABBIT_PASS: guest
    restart: unless-stopped
    networks:
      - communication
    depends_on:
      database-notifications:
        condition: service_started
      schema-registry:
        condition: service_healthy
      configserver:
        condition: service_healthy
      eurekaserver:
        condition: service_healthy

  database-notifications:
    image: mariadb:12.1.2
    container_name: database-notifications
    hostname: database-notifications
    ports:
      - "3306:3306"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
    restart: unless-stopped
    environment:
      TZ: utc
      MARIADB_ROOT_PASSWORD: root123
      MARIADB_DATABASE: db-notifications
      MARIADB_USER: mariadb
      MARIADB_PASSWORD: mariadb
    volumes:
      - db-notifications:/var/lib/mysql
    networks:
      - communication

  api-news:
    image: juniorsmartins/api-news:v0.0.2
    container_name: api-news
    hostname: api-news
    build:
      context: ../api-news
      dockerfile: Dockerfile
      args:
        APP_NAME: "api-news"
        APP_VERSION: "v0.0.2"
        APP_DESCRIPTION: "Microsserviço para registro de notícias."
    ports:
      - "9000:9000"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    environment:
      TZ: utc
      SERVER_PORT: 9000
      SPRING_CLOUD_CONFIG_SERVER_URI: http://configserver:8888
      EUREKA_CLIENT_SERVICEURL_DEFAULTZONE: http://eurekaserver:8761/eureka/
      SPRING_PROFILES_ACTIVE: dev
      DB_HOST: database-news
      DB_PORT: 3306
      DB_NAME: db-news
      MYSQL_USER: mysql123
      MYSQL_PASSWORD: mysql123
      SPRING_RABBITMQ_HOST: "rabbit"
      RABBIT_HOST: rabbit
      RABBIT_PORT: 5672
      RABBIT_USER: guest
      RABBIT_PASS: guest
    restart: unless-stopped
    networks:
      - communication
    depends_on:
      database-news:
        condition: service_started
      schema-registry:
        condition: service_healthy
      configserver:
        condition: service_healthy
      eurekaserver:
        condition: service_healthy

  database-news:
    image: mysql:lts-oraclelinux9
    container_name: database-news
    hostname: database-news
    ports:
      - "3307:3306"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
    restart: unless-stopped
    environment:
      TZ: utc
      MYSQL_ROOT_PASSWORD: root123
      MYSQL_DATABASE: db-news
      MYSQL_USER: mysql123
      MYSQL_PASSWORD: mysql123
    volumes:
      - db-news:/var/lib/mysql
    networks:
      - communication

  api-ias:
    image: juniorsmartins/api-ias:v0.0.2
    container_name: api-ias
    hostname: api-ias
    build:
      context: ../api-ias
      dockerfile: Dockerfile
      args:
        APP_NAME: "api-ias"
        APP_VERSION: "v0.0.2"
        APP_DESCRIPTION: "Microsserviço responsável por fornecer inteligência artificial."
    env_file:
      - envs/.env-api-ias
    ports:
      - "9010:9010"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          memory: 256M
          cpus: '0.3'
    environment:
      TZ: utc
      SERVER_PORT: 9010
      SPRING_CLOUD_CONFIG_SERVER_URI: http://configserver:8888
      EUREKA_CLIENT_SERVICEURL_DEFAULTZONE: http://eurekaserver:8761/eureka/
      SPRING_PROFILES_ACTIVE: dev
      SPRING_RABBITMQ_HOST: "rabbit"
      RABBIT_HOST: rabbit
      RABBIT_PORT: 5672
      REDIS_HOST: redis
      REDIS_PORT: 6379
      OPENAI_BASE_URL: https://api.openai.com
      JAVA_TOOL_OPTIONS: "--enable-native-access=ALL-UNNAMED" # Elimina alguns warnnings
    restart: unless-stopped
    networks:
      - communication
    depends_on:
      schema-registry:
        condition: service_healthy
      configserver:
        condition: service_healthy
      eurekaserver:
        condition: service_healthy
      redis:
        condition: service_healthy

  rabbit:
    image: rabbitmq:3.12-management
    container_name: rabbit
    hostname: rabbit
    ports:
      - "5672:5672"
      - "15672:15672"
    healthcheck:
      test: rabbitmq-diagnostics check_port_connectivity
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 5s
    environment:
      TZ: utc
      RABBITMQ_DEFAULT_USER: guest
      RABBITMQ_DEFAULT_PASS: guest
    restart: unless-stopped
    networks:
      - communication

  redis:
    image: redis:8.4.0
    container_name: redis
    hostname: redis
    ports:
      - "6379:6379"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1024M
    restart: unless-stopped
    environment:
      TZ: utc
      REDIS_HOST: redis
      REDIS_PORT: 6379
    volumes:
      - redis-data:/data
    command: ["redis-server", "--appendonly", "yes"]
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - communication

  redis-insight:
    image: redis/redisinsight:latest
    container_name: redis-insight
    hostname: redis-insight
    ports:
      - "5540:5540"
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy








