server:
  port: ${SERVER_PORT:9050}
spring:
  application:
    name: api_users
  profiles:
    active: default

---
spring:
  config:
    activate:
      on-profile: default

  datasource: # Configura o datasource do banco de dados.
    driver-class-name: org.postgresql.Driver # Especifica o driver JDBC (neste caso, para Postgres).
    url: jdbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5432}/${DB_NAME:db_users} # Define a URL de conexao ao banco.
    username: ${DB_USERNAME:postgres}
    password: ${DB_PASSWORD:postgres}

  jpa: # Configura o JPA/Hibernate.
    hibernate:
      ddl-auto: none # Define a estrategia de criacao do schema do banco de dados. Pode ser 'none', 'validate', 'update', 'create', 'create-drop'.
      naming:
        physical-strategy: org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl # Define a estrategia de nomeacao fisica (padrao). Usar CamelCase no Java e snake_case no banco.
    defer-datasource-initialization: false # True adia a execucao do import.sql ate que o schema JPA esteja inicializado. Usar false com Liquibase.
    properties:
      hibernate: # Configuracoes avancadas do Hibernate.
        format_sql: true # Formata o SQL gerado para melhor legibilidade.
        use_sql_comments: true # Adiciona comentarios ao SQL gerado.
        connection: # Define o nivel de isolamento de transacao.
          isolation: 2 # Nivel 2 de isolamento recomendado para a maioria dos casos. - 1 = READ_UNCOMMITTED, 2 = READ_COMMITTED, 4 = REPEATABLE_READ, 8 = SERIALIZABLE
        cache:
          use_second_level_cache: false # Habilita cache de segundo nivel. False desabilitado para garantir dados sempre atualizados.
          use_query_cache: false # Habilita cache de consultas. False desabilitado para garantir dados sempre atualizados.
        type:
          enumType:
            type: pgsql_enum # Define o mapeamento de enums para PostgreSQL. Usar 'pgsql_enum' para suporte nativo a enums do PostgreSQL.
    open-in-view: false #  Define se o Hibernate deve manter a sessao aberta durante a renderizacao da view. O false e recomendado para evitar problemas de performance e lazy loading.
    show-sql: true # Habilita a exibicao do SQL gerado no console.

  liquibase:
    enabled: true
    change-log: classpath:liquibase/changelog/master.yaml
    default-schema: public

  security: # Configuracao do Sprint Security
    form-login:
      page: /login # Define a URL personalizada (caso precise ser usada em outra parte do sistema)

  messages: # Configuracao de mensagem para login personalizado
    basename: messages

#  Kafka:
#    bootstrap-servers: kafka:9092
#    properties:
#      schema:
#        registry:
#          url: kafka-cluster:8081
#      specific:
#        avro:
#          reader: true
#    topic:
#      event-create-customer: event-create-customer
#    producer:
#      key-serializer: org.apache.kafka.common.serialization.StringSerializer
#      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
#      properties:
#        spring.json.trusted.packages: "*" # Asterisco para confiar em todos os pacotes para desserializacao
#        spring.json.add.type.headers: false # Opcional: Evita headers de tipo para simplicidade

  kafka:
    bootstrap-servers: kafka:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer # Define como serializar chaves (obrigatório)
      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer # Define como serializar o payload/mensagem - pode ser string, json, avro e etc (obrigatório)

      # === Exactly-once (trio sagrado: idempotence, acks e retries) ===
      acks: all # Define se o producer deve esperar confirmação de entrega (0 - Producer nem espera resposta. Envia e esquece / 1 - Producer espera o líder confirmar que gravou. / all ou -1 - Producer espera líder + todas as réplicas ISR confirmarem (ou seja, RF=3 → 3 confirmações).
      enable.idempotence: true # Habilita idempotência (necessário para evitar mensagens duplicadas, incluído em retries). Funciona em conjunto com acks e retries.
      max.in.flight.requests.per.connection: 5 # Permitir múltiplas requisições em voo para maior throughput (padrão 5)
#      retries: # Idempotência não funciona sem (obrigatório). 2147483647 # Integer.MAX_VALUE — valor explícito

      # === Throughput Máximo ===
      batch-size: 131072 # Tamanho máximo (em bytes) que o produtor tenta juntar em um único batch antes de enviar para o broker. Junta várias mensagens num pacote só.
      linger-ms: 5 # Define quanto temo espera até encher o batch (usar obrigatório com batch-size)
      compression-type: zstd # Define como a mensagem será comprimida antes de enviar (none, gzip, snappy, lz4, zstd). Isso reduz o tamanho.

      # === Timeouts Seguros ===
      delivery.timeout.ms: 120001 # Tempo TOTAL para tentar enviar mensagens antes de desistir e jogar exceção (Mesmo que tenha milhões de retries, depois de X tempo no total o produtor desiste e joga exceção). Ele controla o ciclo de vida, incluindo: Todas as tentativas de retry; Espera no batch (linger.ms); Tempo de compressão; Tempo de envio pela rede; Espera pelo ack do broker.
      request.timeout.ms: 60001 # Especifica o tempo máximo unitário por cada tentativa de enviar. Espera a resposta do broker em cada retry.

      properties:
        schema.registry.url: http://kafka:8081 # Endereço do esquema registry (obrigatório se usar Avro)
        auto.register.schemas: true # registra schema automaticamente (dev OK, prod = false)

    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer # Define como desserializar chaves (obrigatório)
      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer # Define como desserializar o payload/mensagem - pode ser string, json, avro e etc (obrigatório)

      # === Estratégia de rebalance ===
      partition.assignment.strategy: org.apache.kafka.clients.consumer.CooperativeStickyAssignor
      group-id: ${spring.application.name}-v1 # Identificador único do grupo de consumidores. Consumers com o mesmo group.id formam um grupo que divide o trabalho (uma partição → um consumer por grupo). O coordinator usa isso para atribuir partições e armazenar offsets no tópico interno __consumer_offsets.
      group.instance.id: ${spring.application.name}-${STATEFULSET_POD_INDEX:0} # Identificador estático do consumidor. Todos os consumidores do grupo ficam tendo o mesmo ID estático. Então quando o consumidor sai, a partição dele não é reatribuída de imediato e espera por um tempo configurável (session.timeout.ms). Daí, quando um consumidor entrar, essa partição é reatribuída sem ter gerado a ação de rebalance geral. Isso evita o rebalanceamento.
      session.timeout.ms: 45001 # Tempo que o coordinator espera heartbeat antes de marcar o consumidor como morto (padrão 45000).

      # === Forma de leitura e garantia de entrega ===
      isolation-level: read_committed # evita ler dados de transações não commitadas (verificar se produtor precisa de transaction-id-prefix: tx-${spring.application.name} em conjunto). Só usar quando salvar no banco.
      auto-offset-reset: latest # latest lê a partir da mensagem mais recente do tópico / earliest lê todas as mensagens do tópico desde o início. Recomendado latest em produção.
      enable-auto-commit: false # O false permite controle sobre o commit (manual ou via Spring). Spring Kafka gerencia com @KafkaListener e Acknowledgment. Obrigatório false em produção.
      # enable-auto-commit false precisa de tópico DLT

      # === Performance e Resiliência ===
      max-poll-records: 1001 # Mais mensagens por poll → menos chamadas de rede (padrão é 500)
      max.poll.interval.ms: 600001 # Tempo máximo entre polls → se passar, expulsa do grupo.
      request-timeout-ms: 60001 # Evita timeout falso com rede ruim (padrão é 30000)

      # === Schema Registry ===
      properties:
        schema.registry.url: http://kafka:8081 # obrigatório com Avro
        specific.avro.reader: true # Usa SpecificRecord (classes geradas a partir do Avro), não GenericRecord.

    topic:
      events.customer-created: events.customer-created-v1
      min.insync.replicas: 2 # O min.insync.replicas configuração trabalha em conjunto com acks=all para controlar a durabilidade.


