server:
  port: ${SERVER_PORT:9050}
spring:
  application:
    name: api_users
  profiles:
    active: default

---
spring:
  config:
    activate:
      on-profile: default

  datasource: # Configura o datasource do banco de dados.
    driver-class-name: org.postgresql.Driver # Especifica o driver JDBC (neste caso, para Postgres).
    url: jdbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5432}/${DB_NAME:db_users} # Define a URL de conexao ao banco.
    username: ${DB_USERNAME:postgres}
    password: ${DB_PASSWORD:postgres}

  jpa: # Configura o JPA/Hibernate.
    hibernate:
      ddl-auto: none # Define a estrategia de criacao do schema do banco de dados. Pode ser 'none', 'validate', 'update', 'create', 'create-drop'.
      naming:
        physical-strategy: org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl # Define a estrategia de nomeacao fisica (padrao). Usar CamelCase no Java e snake_case no banco.
    defer-datasource-initialization: false # True adia a execucao do import.sql ate que o schema JPA esteja inicializado. Usar false com Liquibase.
    properties:
      hibernate: # Configuracoes avancadas do Hibernate.
        format_sql: true # Formata o SQL gerado para melhor legibilidade.
        use_sql_comments: true # Adiciona comentarios ao SQL gerado.
        connection: # Define o nivel de isolamento de transacao.
          isolation: 2 # Nivel 2 de isolamento recomendado para a maioria dos casos. - 1 = READ_UNCOMMITTED, 2 = READ_COMMITTED, 4 = REPEATABLE_READ, 8 = SERIALIZABLE
        cache:
          use_second_level_cache: false # Habilita cache de segundo nivel. False desabilitado para garantir dados sempre atualizados.
          use_query_cache: false # Habilita cache de consultas. False desabilitado para garantir dados sempre atualizados.
        type:
          enumType:
            type: pgsql_enum # Define o mapeamento de enums para PostgreSQL. Usar 'pgsql_enum' para suporte nativo a enums do PostgreSQL.
    open-in-view: false #  Define se o Hibernate deve manter a sessao aberta durante a renderizacao da view. O false e recomendado para evitar problemas de performance e lazy loading.
    show-sql: true # Habilita a exibicao do SQL gerado no console.

  liquibase:
    enabled: true
    change-log: classpath:liquibase/changelog/master.yaml
    default-schema: public

  security: # Configuracao do Sprint Security
    form-login:
      page: /login # Define a URL personalizada (caso precise ser usada em outra parte do sistema)

  messages: # Configuracao de mensagem para login personalizado
    basename: messages

#  Kafka:
#    bootstrap-servers: kafka:9092
#    properties:
#      schema:
#        registry:
#          url: kafka-cluster:8081
#      specific:
#        avro:
#          reader: true
#    topic:
#      event-create-customer: event-create-customer
#    producer:
#      key-serializer: org.apache.kafka.common.serialization.StringSerializer
#      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
#      properties:
#        spring.json.trusted.packages: "*" # Asterisco para confiar em todos os pacotes para desserializacao
#        spring.json.add.type.headers: false # Opcional: Evita headers de tipo para simplicidade

  kafka:
    bootstrap-servers: kafka:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
      compression-type: zstd # (none, gzip, snappy, lz4, zstd)
      max.in.flight.requests.per.connection: 5 # Permitir múltiplas requisições em voo para maior throughput (padrão 5)
      # Padrão exactly-once (idempotence, acks e retries)
      enable.idempotence: true # Habilita idempotência (necessário para evitar duplicatas em retries)
      acks: -1 # Idempotência não funciona sem (0 - Producer nem espera resposta. Envia e esquece / 1 - Producer espera o líder confirmar que gravou no log (padrão). / all ou -1 - Producer espera líder + todas as réplicas ISR confirmarem (ou seja, RF=3 → 3 confirmações).
#      retries: # Idempotência não funciona sem
      properties:
        schema.registry.url: http://kafka:8081 # obrigatório com Avro
        specific.avro.reader: true
        auto.register.schemas: true # registra schema automaticamente (dev OK, prod = false)
    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
      group-id: group-api-users-customer
      auto-offset-reset: earliest # Ou latest, dependendo do caso de uso - earliest lê desde o início do tópico
      enable-auto-commit: false # Spring Kafka gerencia commit manual ou com listener
      isolation-level: read_committed # evita ler dados de transações não commitadas
      properties:
        schema.registry.url: http://kafka:8081 # obrigatório com Avro
        specific.avro.reader: true
    topic:
      event-create-customer: event-create-customer

